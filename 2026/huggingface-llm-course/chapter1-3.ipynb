{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d913c24",
   "metadata": {},
   "source": [
    "# Chapter 1 - 3: Transformers, what can they do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a261c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: evaluate in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: sentencepiece in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: transformers in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (4.57.6)\n",
      "Requirement already satisfied: torch in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (2.9.1)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-12.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: filelock in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (2.4.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: setuptools in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading pillow-12.1.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-12.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate sentencepiece transformers torch Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ed9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b733e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9982948899269104}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a Hugging Face course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba83acf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9982948899269104},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I've been waiting for a Hugging Face course my whole life.\", \"I hate this so much!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1380a",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "984d8f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library.',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8719869256019592, 0.09406612813472748, 0.03394696116447449]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library.\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c78da80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One day I will see the world.',\n",
       " 'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
       " 'scores': [0.9941898584365845,\n",
       "  0.9429399371147156,\n",
       "  0.0060537466779351234,\n",
       "  0.0020010927692055702]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = [\"travel\", \"cooking\", \"dancing\", \"exploration\"]\n",
    "classifier('One day I will see the world.', candidate_labels=candidate_labels, multi_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17964b",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1cb7ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to use the basic tools of learning Chinese without getting too technical or too technical. We will teach you how to use the basic tools of learning Chinese without getting too technical or too technical.\\n\\nLearn from the examples\\n\\nTake the time to take a look at the examples and see how they are used. If they are your own, don't know what you are doing, don't want to learn from an instructor, don't want to learn from anyone, don't want to learn from anyone, don't want to learn from somebody who is your teacher, or you just want to learn from someone who you know well, we won't bother learning from anyone.\\n\\nYou can learn from the examples to help you make your own mistakes. We will focus on the most common mistakes, to help you make your own mistakes.\\n\\nIf you don't want to learn from anyone, we will give you a free trial of the course. If you don't want to learn from someone, we will give you a free trial of the course.\\n\\nTo learn more, take an online course, you can find it at the following locations:\\n\\nChina\\n\\nKorea\\n\\nTaiwan\\n\\nHong Kong\\n\\nTaiwanese\\n\\nTo learn more about\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator('In this course, we will teach you how to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to read, write, and speak these codes. You will also learn how to use them to transmit messages, store information, and even communicate with others over long distances!\\n\\nThis course is designed for anyone who wants to learn the basics of coding and communication. Even if you have never written or spoken a code before, don't worry - we'll start with the basics and build up from there. We'll use simple examples and step-by-step instructions to help you understand these concepts.\\n\\nGet ready to dive into the fascinating world of code languages! Let's begin our journey together.\"},\n",
       " {'generated_text': 'In this course, we will teach you how to use some of the more popular programming languages to build your own basic web applications. You will learn how to use HTML, CSS, and JavaScript to create web pages. You will learn the fundamentals of HTML, CSS, and JavaScript, and how to use them to create basic web pages.\\n\\nWe will cover:\\n* HTML: The markup language of the web. Learn how to create simple HTML documents and how to use them to create basic web pages.\\n* CSS: The style sheet language of the web. Learn how to create stylesheets to style web pages.\\n* JavaScript: A programming language that is used to build dynamic web pages. Learn how to use JavaScript to create interactive web pages.\\n\\nWe will also cover some basic web development techniques. We will learn how to use the Document Object Model (DOM) to manipulate web pages, how to use JavaScript to create user interfaces, and how to use Ajax to create dynamic web pages.\\n\\nTo complete this course, you will need to have some basic knowledge of HTML and CSS, as well as a basic understanding of the web. However, this course is designed to be easy to follow and to be self-contained.\\n\\nAfter completing this course, you should'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator('In this course, we will teach you how to', max_length=30, num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d26d3a",
   "metadata": {},
   "source": [
    "## Mask filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccee7925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19620011746883392,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052743315696716,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask')\n",
    "unmasker('This course will teach you all about <mask> models.', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0a32a",
   "metadata": {},
   "source": [
    "## Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cacb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "/Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9981694),\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9796019),\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline('ner', grouped_entities=True) # grouped_entities=True groups the entities like Hugging and Face into one entity\n",
    "ner('My name is Sylvain and I work at Hugging Face in Brooklyn.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82d0d8",
   "metadata": {},
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e19f45a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6385907530784607, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline('question-answering')\n",
    "question_answerer(\n",
    "    question='Where do I work?',\n",
    "    context='My name is Sylvain and I work at Hugging Face in Brooklyn.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e489f6",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58519e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' China and India graduate six and eight times as many traditional engineers as the U.S. as does other industrial countries . America suffers an increasingly serious decline in the number of engineering graduates and a lack of well-educated engineers . There are declining offerings in engineering subjects dealing with infrastructure, infrastructure, the environment, and related issues .'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline('summarization')\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc740519",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d67d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-fr-en')\n",
    "translator('Ce cours est produit par Hugging Face.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53aaa58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Este curso es producido por Hugging Face.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-en-es')\n",
    "translator('This course is produced by Hugging Face.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5061891",
   "metadata": {},
   "source": [
    "## Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4fa949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielwohlgemuth/Code/experiments/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'lynx, catamount', 'score': 0.4334994852542877}, {'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 'score': 0.03479622304439545}, {'label': 'snow leopard, ounce, Panthera uncia', 'score': 0.03240189701318741}, {'label': 'Egyptian cat', 'score': 0.02394481934607029}, {'label': 'tiger cat', 'score': 0.02288917638361454}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_classifier = pipeline(task='image-classification', model='google/vit-base-patch16-224')\n",
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59842af0",
   "metadata": {},
   "source": [
    "## Automatic speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decce5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' I have a dream that one day, this nation will rise up, live out the true meaning of its creed.'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline('automatic-speech-recognition', model='openai/whisper-tiny.en')\n",
    "result = transcriber('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac')\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
